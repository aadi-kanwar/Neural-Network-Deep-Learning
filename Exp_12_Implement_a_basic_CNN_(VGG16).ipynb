{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM34lvSqgC0z/zgqMSHDDcu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadi-kanwar/Neural-Network-Deep-Learning/blob/main/Exp_12_Implement_a_basic_CNN_(VGG16).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Required Libraries and Dependencies"
      ],
      "metadata": {
        "id": "95JhGe0M9BF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "metadata": {
        "id": "R8Xvh-we9j9T"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Parameters"
      ],
      "metadata": {
        "id": "r8Z2ttzW9rDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "num_classes = 2     # Cats and Dogs"
      ],
      "metadata": {
        "id": "nrgEpbS79qDq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the cats abd dogs dataset"
      ],
      "metadata": {
        "id": "E7W--pk292O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
        "zip_file = tf.keras.utils.get_file(\"cat_and_dogs_filtered.zip\", dataset_url, extract=True)\n",
        "base_dir = os.path.join(os.path.dirname(zip_file), 'cats_and_dogs_filtered')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYs99ybE91aL",
        "outputId": "1797a93f-85fb-42c3-b4bf-cf35d7b74d0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "\u001b[1m68606236/68606236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set path for train and validation directories"
      ],
      "metadata": {
        "id": "bPf8o2ug-Vg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "metadata": {
        "id": "qkEWUGl1-Teu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the pre-trained VGG16 model without the top layer"
      ],
      "metadata": {
        "id": "U6gmMZXY_ogq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F89EsDL-fBQ",
        "outputId": "1a4aca42-a5ce-41ea-aa41-7892f0f52a7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freeze the layers in the base model to retain pre-trained weights"
      ],
      "metadata": {
        "id": "Um1RzJlO_36P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "EC3hoNRH_282"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add custom layers on top of the base model for our specific classification task"
      ],
      "metadata": {
        "id": "KyO4WfVHADrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)   # Flatten the output to 1D\n",
        "x = Dense(512, activation='relu')(x)    # Add a dense layer with 512 units\n",
        "x = Dropout(0.5)(x)     # Add dropout for regularization\n",
        "predictions = Dense(num_classes, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "ToLL67uzAW92"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine base models and custom layers"
      ],
      "metadata": {
        "id": "11cP87AcAlf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "metadata": {
        "id": "G11diN9zAk4m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the model"
      ],
      "metadata": {
        "id": "DgK7A2SpBLus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = Adam(learning_rate = 0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "UJlWfeNGCCdO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data with ImageDataGenerator for data augumentation"
      ],
      "metadata": {
        "id": "xT024cJMCLZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1.0/255,\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1O5FN5NCC1O",
        "outputId": "88e15e64-9d65-4307-cd0c-2931d90666b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "uBNFObUIEvOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = validation_generator.samples // batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A4QC5TBExRv",
        "outputId": "89d25d1f-4e73-411d-f1fc-3f8b2fdb4bc8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 445ms/step - accuracy: 0.8646 - loss: 0.2867 - val_accuracy: 0.9173 - val_loss: 0.1963\n",
            "Epoch 2/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8750 - loss: 0.3869 - val_accuracy: 0.8750 - val_loss: 0.1884\n",
            "Epoch 3/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 428ms/step - accuracy: 0.8560 - loss: 0.3251 - val_accuracy: 0.9083 - val_loss: 0.2127\n",
            "Epoch 4/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9062 - loss: 0.2456 - val_accuracy: 0.8750 - val_loss: 0.1339\n",
            "Epoch 5/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 449ms/step - accuracy: 0.8827 - loss: 0.2701 - val_accuracy: 0.9093 - val_loss: 0.2230\n",
            "Epoch 6/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7500 - loss: 0.4487 - val_accuracy: 0.7500 - val_loss: 0.3405\n",
            "Epoch 7/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 456ms/step - accuracy: 0.8553 - loss: 0.2969 - val_accuracy: 0.9294 - val_loss: 0.1811\n",
            "Epoch 8/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8750 - loss: 0.2588 - val_accuracy: 1.0000 - val_loss: 0.0608\n",
            "Epoch 9/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 437ms/step - accuracy: 0.8860 - loss: 0.2728 - val_accuracy: 0.9294 - val_loss: 0.1800\n",
            "Epoch 10/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.1740 - val_accuracy: 0.8750 - val_loss: 0.2572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model"
      ],
      "metadata": {
        "id": "jS3ciZdyErrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da823QdpDXKM",
        "outputId": "ce4b6de0-b5e5-4439-c6af-068771003505"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - accuracy: 0.9387 - loss: 0.1759\n",
            "Validation Loss: 0.2086\n",
            "Validation Accuracy: 0.9260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "aMButMENFhJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save =(\"VGG16_transfer_learning_cats_dogs.h5\")"
      ],
      "metadata": {
        "id": "g19fNU8eFdrV"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}