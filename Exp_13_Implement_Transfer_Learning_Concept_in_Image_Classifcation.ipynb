{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNVcSZmIlKO8fgfN2leFRjH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadi-kanwar/Neural-Network-Deep-Learning/blob/main/Exp_13_Implement_Transfer_Learning_Concept_in_Image_Classifcation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import required libraries and dependencies"
      ],
      "metadata": {
        "id": "Sh953Fq4EBlo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4nIA9jMiDUuA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Parametes"
      ],
      "metadata": {
        "id": "0E9vYotjGY-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "num_classes = 2     # Cats and Dogs"
      ],
      "metadata": {
        "id": "uDVi80BaGZ_B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Cats & Dags Dataset from Tensorflow Datasets"
      ],
      "metadata": {
        "id": "gvhQM-yNHB16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
        "zip_file = tf.keras.utils.get_file(\"cat_and_dogs_filtered.zip\", dataset_url, extract=True)\n",
        "base_dir = os.path.join(os.path.dirname(zip_file), 'cats_and_dogs_filtered')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syB7Q619HBL7",
        "outputId": "c4c472ec-d422-4e08-962a-2034b3427cc7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "\u001b[1m68606236/68606236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set path for train and validation directories"
      ],
      "metadata": {
        "id": "AmJBblx2HL89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "metadata": {
        "id": "2PJiCWOQHJxB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the pre-trained VGG16 model without the top layer"
      ],
      "metadata": {
        "id": "ENK379TEIDY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfiz92xnHbjS",
        "outputId": "e4e11557-3563-462f-cd8b-8180cd9b74de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freeze the layers in the base model to retain pre-trained weights"
      ],
      "metadata": {
        "id": "1ScVGb1CIGKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "3gmxa6j8IG4L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add custom layers on top of the base model for our specific classification task"
      ],
      "metadata": {
        "id": "YDKz5dA8IXLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)   # Flatten the output to 1D\n",
        "x = Dense(512, activation='relu')(x)    # Add a dense layer with 512 units\n",
        "x = Dropout(0.5)(x)     # Add dropout for regularization\n",
        "predictions = Dense(num_classes, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "FMJ3bn64IL3C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine base models and custom layers"
      ],
      "metadata": {
        "id": "aPYW08RvIcBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "metadata": {
        "id": "sZlMxz-UIadH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the model"
      ],
      "metadata": {
        "id": "7RZQfYM0Iqv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = Adam(learning_rate = 0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "cuim_7VDIeTE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data with ImageDataGenerator for data augumentation"
      ],
      "metadata": {
        "id": "wrJy1sHkJlaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1.0/255,\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfULKmI9IpLq",
        "outputId": "7c2b5b31-d30a-4b58-c863-c405e58fe2cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "gfvqS19GKDfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = validation_generator.samples // batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psp-AiTqJr-Y",
        "outputId": "615a7528-1bdc-45b2-eb3b-50238d3d74c3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 491ms/step - accuracy: 0.8673 - loss: 0.2820 - val_accuracy: 0.9234 - val_loss: 0.1975\n",
            "Epoch 2/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9062 - loss: 0.2265 - val_accuracy: 0.8750 - val_loss: 0.2350\n",
            "Epoch 3/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 481ms/step - accuracy: 0.8792 - loss: 0.2803 - val_accuracy: 0.9274 - val_loss: 0.1888\n",
            "Epoch 4/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9062 - loss: 0.2892 - val_accuracy: 0.8750 - val_loss: 0.2111\n",
            "Epoch 5/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 480ms/step - accuracy: 0.8769 - loss: 0.2646 - val_accuracy: 0.9274 - val_loss: 0.1903\n",
            "Epoch 6/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7812 - loss: 0.4471 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
            "Epoch 7/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 475ms/step - accuracy: 0.8750 - loss: 0.2708 - val_accuracy: 0.9304 - val_loss: 0.1846\n",
            "Epoch 8/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8750 - loss: 0.3158 - val_accuracy: 0.7500 - val_loss: 0.5286\n",
            "Epoch 9/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 487ms/step - accuracy: 0.8962 - loss: 0.2618 - val_accuracy: 0.9153 - val_loss: 0.1979\n",
            "Epoch 10/10\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8438 - loss: 0.2721 - val_accuracy: 1.0000 - val_loss: 0.1502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model"
      ],
      "metadata": {
        "id": "22EzlEmLL1V4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-u1TCH5LJCY",
        "outputId": "8f6b665b-448f-40f4-a062-c55e84bca614"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 0.9286 - loss: 0.1872\n",
            "Validation Loss: 0.1899\n",
            "Validation Accuracy: 0.9270\n"
          ]
        }
      ]
    }
  ]
}